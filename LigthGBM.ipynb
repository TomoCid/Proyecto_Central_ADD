{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa11017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52cbcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def agregar_lags(df, columna, lags):\n",
    "    \"\"\"Agrega variables de retardo (lags) al DataFrame.\"\"\"\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df[columna].shift(lag)\n",
    "    return df\n",
    "\n",
    "def agregar_medias_moviles(df, columna, ventanas):\n",
    "    \"\"\"Agrega variables de medias móviles al DataFrame.\"\"\"\n",
    "    for ventana in ventanas:\n",
    "        df[f'media_movil_{ventana}'] = df[columna].shift(1).rolling(window=ventana, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "def agregar_variables_ciclicas(df, columna_mes, columna_fecha):\n",
    "    \"\"\"Agrega variables cíclicas seno/coseno para mes y día de la semana.\"\"\"\n",
    "    df['mes_sin'] = np.sin(2 * np.pi * df[columna_mes] / 12)\n",
    "    df['mes_cos'] = np.cos(2 * np.pi * df[columna_mes] / 12)\n",
    "    df['dia_semana_sin'] = np.sin(2 * np.pi * pd.to_datetime(df[columna_fecha]).dt.weekday / 7)\n",
    "    df['dia_semana_cos'] = np.cos(2 * np.pi * pd.to_datetime(df[columna_fecha]).dt.weekday / 7)\n",
    "    return df\n",
    "\n",
    "def agregar_ewma(df, columna, spans):\n",
    "    \"\"\"Agrega variables de Media Móvil Exponencial (EWMA) al DataFrame.\"\"\"\n",
    "    for span in spans:\n",
    "        df[f'ewma_{span}'] = df[columna].shift(1).ewm(span=span, adjust=False).mean()\n",
    "    return df\n",
    "\n",
    "def obtener_semestre(mes):\n",
    "    \"\"\"Define la variable Semestre (1, 2 o 0).\"\"\"\n",
    "    if 3 <= mes <= 7:\n",
    "        return 1\n",
    "    elif 8 <= mes <= 12:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc097f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado desde 'Datasets/daily_counts_full.csv'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    daily_counts_full = pd.read_csv(\"Datasets/accesos_biblioteca.csv\")\n",
    "    print(\"Dataset cargado desde 'Datasets/daily_counts_full.csv'\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: No se encontró el archivo 'daily_counts_full.csv'.\")\n",
    "    exit(1)\n",
    "\n",
    "# Aplicar transformaciones y crear features\n",
    "for col in ['Accesos']:\n",
    "    daily_counts_full[col] = daily_counts_full[col].fillna(0).astype(int)\n",
    "daily_counts_full['Fecha'] = pd.to_datetime(daily_counts_full['Fecha'])\n",
    "daily_counts_full = daily_counts_full[\n",
    "    daily_counts_full['Fecha'].dt.weekday != 6 # Eliminar domingos\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Generar features de series temporales\n",
    "daily_counts_full = agregar_medias_moviles(daily_counts_full, 'Accesos', [7, 14, 30])\n",
    "daily_counts_full = agregar_variables_ciclicas(daily_counts_full, 'Mes', 'Fecha')\n",
    "daily_counts_full = agregar_ewma(daily_counts_full, 'Accesos', [7, 14, 30])\n",
    "daily_counts_full['Semestre'] = daily_counts_full['Mes'].apply(obtener_semestre)\n",
    "\n",
    "# Generar Semana_Semestre y Semana_Certamen\n",
    "def semana_en_semestre(row):\n",
    "    if row['Semestre'] == 1:\n",
    "        inicio = pd.Timestamp(year=row['Año'], month=3, day=1)\n",
    "    elif row['Semestre'] == 2:\n",
    "        inicio = pd.Timestamp(year=row['Año'], month=8, day=1)\n",
    "    else:\n",
    "        return np.nan\n",
    "    return ((row['Fecha'] - inicio).days // 7) + 1\n",
    "\n",
    "daily_counts_full['Semana_Semestre'] = daily_counts_full.apply(semana_en_semestre, axis=1)\n",
    "daily_counts_full['Semana_Certamen'] = daily_counts_full['Semana_Semestre'].isin([6, 7]).astype(int)\n",
    "\n",
    "# Agregar Lags\n",
    "daily_counts_full = agregar_lags(daily_counts_full, 'Accesos', [7, 14, 21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe783ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Preparación de Datos Finalizada\n",
      "Datos de entrenamiento: 256 | Datos de prueba: 64\n",
      "Número de Features Exógenas: 14\n"
     ]
    }
   ],
   "source": [
    "daily_counts_full = daily_counts_full.dropna().reset_index(drop=True)\n",
    "\n",
    "# Usando el conjunto completo de features para un modelo robusto y consistente\n",
    "FEATURES = ['Semana_Certamen', 'media_movil_7', 'media_movil_14', 'media_movil_30',\n",
    "            'mes_sin', 'mes_cos', 'dia_semana_sin', 'dia_semana_cos',\n",
    "            'lag_7', 'lag_14', 'lag_21', 'ewma_7', 'ewma_14', 'ewma_30']\n",
    "TARGET = 'Accesos'\n",
    "\n",
    "X = daily_counts_full[FEATURES]\n",
    "y = daily_counts_full[TARGET]\n",
    "\n",
    "# 80/20 split, shuffle=False para series temporales\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# Data Augmentation para el set de entrenamiento\n",
    "X_train_aug = [X_train.copy()]\n",
    "y_train_aug = [y_train.copy()]\n",
    "N_AUGMENTATIONS = 4\n",
    "\n",
    "for i in range(N_AUGMENTATIONS):\n",
    "    if i % 2 == 0:\n",
    "        y_new = y_train * np.random.uniform(0.95, 1.05, len(y_train))\n",
    "    else:\n",
    "        y_new = y_train + np.random.normal(0, y_train.std() * 0.02, len(y_train))\n",
    "    \n",
    "    df_new = X_train.copy()\n",
    "    df_new['Accesos'] = y_new\n",
    "\n",
    "    # Recalcular features (manteniendo las columnas no dependientes del target)\n",
    "    df_new = df_new.drop(columns=[col for col in df_new.columns if 'media_movil' in col or 'ewma' in col or 'lag_' in col], errors='ignore')\n",
    "    df_new = agregar_medias_moviles(df_new, 'Accesos', [7, 14, 30])\n",
    "    df_new = agregar_ewma(df_new, 'Accesos', [7, 14, 30])\n",
    "    df_new = agregar_lags(df_new, 'Accesos', [7, 14, 21])\n",
    "\n",
    "    df_new = df_new.dropna().reset_index(drop=True)\n",
    "    \n",
    "    X_train_aug.append(df_new[FEATURES])\n",
    "    y_train_aug.append(df_new['Accesos'])\n",
    "\n",
    "X_train_final = pd.concat(X_train_aug)\n",
    "y_train_final = pd.concat(y_train_aug)\n",
    "\n",
    "print(f\"\\n\")\n",
    "print(f\"Preparación de Datos Finalizada\")\n",
    "print(f\"Datos de entrenamiento: {len(y_train)} | Datos de prueba: {len(y_test)}\")\n",
    "print(f\"Número de Features Exógenas: {len(FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4721b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando entrenamiento y ajuste de hiperparámetros de LightGBM...\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento y Evaluación con LightGBM\n",
    "# Configuración de búsqueda de hiperparámetros\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 700],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [20, 31, 40],\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "}\n",
    "\n",
    "print(\"\\nIniciando entrenamiento y ajuste de hiperparámetros de LightGBM...\")\n",
    "\n",
    "# 1. Búsqueda de Hyperparámetros\n",
    "grid_search = GridSearchCV(\n",
    "    lgb.LGBMRegressor(random_state=42, n_jobs=-1, objective='regression'),\n",
    "    param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train_final, y_train_final)\n",
    "\n",
    "print(f'Mejores parámetros para LightGBM: {grid_search.best_params_}')\n",
    "\n",
    "# 2. Entrenamiento del modelo final con los mejores parámetros\n",
    "best_params = grid_search.best_params_\n",
    "model = lgb.LGBMRegressor(**best_params, random_state=42, n_jobs=-1, objective='regression')\n",
    "model.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Guardar el modelo\n",
    "os.makedirs(os.path.dirname('Archivos Auxiliares/'), exist_ok=True)\n",
    "joblib.dump(model, 'Archivos Auxiliares/modelo_LightGBM.pkl')\n",
    "print(\"Modelo LightGBM guardado como 'Archivos Auxiliares/modelo_LightGBM.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación de rendimiento\n",
    "predicted = model.predict(X_test)\n",
    "predicted = np.maximum(predicted, 0)\n",
    "\n",
    "# Cálculo de métricas\n",
    "mse = mean_squared_error(y_test, predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, predicted)\n",
    "r2 = r2_score(y_test, predicted)\n",
    "\n",
    "print(\"\\n--- Evaluación de rendimiento de LightGBM en el set de prueba ---\")\n",
    "print(f\"R²: {r2:.2f}\")\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")\n",
    "print(f\"Error Cuadrático Medio Raíz (RMSE): {rmse:.2f}\")\n",
    "print(f\"Error Absoluto Medio (MAE): {mae:.2f}\")\n",
    "\n",
    "# Graficar resultados de la predicción (Real vs. Predicción en el test set)\n",
    "results_df = pd.DataFrame({\n",
    "    'Índice': X_test.index,\n",
    "    'Real': y_test,\n",
    "    'Predicción': predicted\n",
    "}).sort_values(by='Índice')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results_df['Índice'], results_df['Real'], label='Real', color='blue', linewidth=2)\n",
    "plt.plot(results_df['Índice'], results_df['Predicción'], label='Predicción', color='red', linestyle='--', linewidth=2)\n",
    "plt.title('LightGBM: Accesos reales vs. predicción en el set de prueba', fontsize=14)\n",
    "plt.xlabel('Índice', fontsize=12)\n",
    "plt.ylabel('Número de Accesos', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lightgbm_predicciones.png')\n",
    "\n",
    "\n",
    "# Graficar importancia de variables\n",
    "importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({\"Feature\": FEATURES, \"Importance\": importances})\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color='skyblue')\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"LightGBM: Importancia de variables\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.tight_layout()\n",
    "plt.savefig('lightgbm_importancia.png')\n",
    "\n",
    "print(\"\\nSe han generado las siguientes visualizaciones:\")\n",
    "print(\"- lightgbm_predicciones.png (Comparación de valores reales vs. predichos)\")\n",
    "print(\"- lightgbm_importancia.png (Importancia de las variables)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
