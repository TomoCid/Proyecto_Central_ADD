{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09bae0e2-4490-4df1-9537-d4aa263830c1",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973652d5-bbee-4713-a125-1f60eed7278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "import joblib\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6825a2a0-ab1b-4f0e-ba4d-5d92358077e5",
   "metadata": {},
   "source": [
    "# Preprocesado de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e720fa-f2ef-40d7-aa75-1444b0ed4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_lags(df, columna, lags):\n",
    "    for lag in lags:\n",
    "        df[f'lag_{lag}'] = df[columna].shift(lag)\n",
    "    return df\n",
    "\n",
    "def agregar_medias_moviles(df, columna, ventanas):\n",
    "    for ventana in ventanas:\n",
    "        df[f'media_movil_{ventana}'] = df[columna].shift(1).rolling(window=ventana, min_periods=1).mean()\n",
    "    return df\n",
    "\n",
    "def agregar_variables_ciclicas(df, columna_mes, columna_fecha):\n",
    "    df['mes_sin'] = np.sin(2 * np.pi * df[columna_mes] / 12)\n",
    "    df['mes_cos'] = np.cos(2 * np.pi * df[columna_mes] / 12)\n",
    "    df['dia_semana_sin'] = np.sin(2 * np.pi * pd.to_datetime(df[columna_fecha]).dt.weekday / 7)\n",
    "    df['dia_semana_cos'] = np.cos(2 * np.pi * pd.to_datetime(df[columna_fecha]).dt.weekday / 7)\n",
    "    return df\n",
    "\n",
    "def agregar_ewma(df, columna, spans):\n",
    "    for span in spans:\n",
    "        df[f'ewma_{span}'] = df[columna].shift(1).ewm(span=span, adjust=False).mean()\n",
    "    return df\n",
    "\n",
    "def transformacion_a_clasificacion(df, class_range):\n",
    "    max = ((df_r['Accesos'].max())//class_range)+2\n",
    "    bins = [0]\n",
    "    labels = []\n",
    "    for i in range(max):\n",
    "        bins.append((i+1)*class_range)\n",
    "        labels.append(i)\n",
    "    df_r['Accesos'] = pd.cut(df_r['Accesos'], bins=bins, labels=labels, right=False)\n",
    "    return df\n",
    "def obtener_semestre(mes):\n",
    "    if 3 <= mes <= 7:\n",
    "        return 1  # Primer semestre\n",
    "    elif 8 <= mes <= 12:\n",
    "        return 2  # Segundo semestre\n",
    "    else:\n",
    "        return 0  # Fuera de semestre (enero, febrero)\n",
    "    \n",
    "def obtener_semana_semestre(fecha):\n",
    "    mes = fecha.month\n",
    "    dia = fecha.day\n",
    "    if 3 <= mes <= 7:\n",
    "        inicio_semestre = datetime(fecha.year, 3, 1)\n",
    "    elif 8 <= mes <= 12:\n",
    "        inicio_semestre = datetime(fecha.year, 8, 1)\n",
    "    else:\n",
    "        return 0  # Fuera de semestre\n",
    "    delta = fecha - inicio_semestre\n",
    "    semana_semestre = delta.days // 7 + 1\n",
    "    return semana_semestre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe583a2-2de4-4f08-86d1-e74489773e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"Datasets/accesos_biblioteca.csv\")\n",
    "    print(\"Dataset cargado desde 'Datasets/accesos_biblioteca.csv'\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: No se encontró el archivo 'accesos_biblioteca.csv'.\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a0972-41d0-4bb6-8489-fb1794511e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Accesos']:\n",
    "    df[col] = df[col].fillna(0).astype(int)\n",
    "\n",
    "df = df[\n",
    "    pd.to_datetime(df['Fecha']).dt.weekday != 6\n",
    "].reset_index(drop=True)\n",
    "\n",
    "df = agregar_medias_moviles(df, 'Accesos', [7, 14, 30])\n",
    "df = agregar_variables_ciclicas(df, 'Mes', 'Fecha')\n",
    "df = agregar_ewma(df, 'Accesos', [7, 14, 30])\n",
    "\n",
    "df['Semestre'] = df['Mes'].apply(obtener_semestre)\n",
    "df['Semana_Semestre'] = pd.to_datetime(df['Fecha']).apply(obtener_semana_semestre)\n",
    "\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "\n",
    "df = agregar_lags(df, 'Accesos', [7, 14, 21])\n",
    "df = transformacion_a_clasificacion(df, 500)\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ca532-71a6-4aa4-aa24-30719b9f7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Fecha', 'Accesos'])\n",
    "y = df['Accesos']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Datos de entrenamiento: {len(X_train)}\")\n",
    "print(f\"Datos de prueba: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3a0877c-d2ba-4a3a-95a4-3055845170c8",
   "metadata": {},
   "source": [
    "try:\n",
    "    daily_counts_full = pd.read_csv(\"Datasets/accesos_biblioteca.csv\")\n",
    "    print(\"Dataset cargado desde 'Datasets/daily_counts_full.csv'\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: No se encontró el archivo 'daily_counts_full.csv'.\")\n",
    "    exit(1)\n",
    "\n",
    "# A. Feature Engineering (Repetimos los pasos para un DF limpio)\n",
    "for col in ['Accesos']:\n",
    "    daily_counts_full[col] = daily_counts_full[col].fillna(0).astype(int)\n",
    "daily_counts_full['Fecha'] = pd.to_datetime(daily_counts_full['Fecha'])\n",
    "daily_counts_full = daily_counts_full[\n",
    "    daily_counts_full['Fecha'].dt.weekday != 6 \n",
    "].reset_index(drop=True)\n",
    "\n",
    "daily_counts_full = agregar_medias_moviles(daily_counts_full, 'Accesos', [7, 14, 30])\n",
    "daily_counts_full = agregar_variables_ciclicas(daily_counts_full, 'Mes', 'Fecha')\n",
    "daily_counts_full = agregar_ewma(daily_counts_full, 'Accesos', [7, 14, 30])\n",
    "daily_counts_full['Semestre'] = daily_counts_full['Mes'].apply(obtener_semestre)\n",
    "daily_counts_full['Semana_Semestre'] = daily_counts_full.apply(semana_en_semestre, axis=1)\n",
    "daily_counts_full['Semana_Certamen'] = daily_counts_full['Semana_Semestre'].isin([6, 7]).astype(int)\n",
    "daily_counts_full = agregar_lags(daily_counts_full, 'Accesos', [7, 14, 21])\n",
    "\n",
    "\n",
    "# B. Preparación del DF en formato Prophet (ds, y)\n",
    "data_prophet = daily_counts_full.copy()\n",
    "data_prophet.rename(columns={'Accesos': 'y'}, inplace=True)\n",
    "data_prophet['ds'] = data_prophet.index\n",
    "\n",
    "# Creacion de los rangos de clasificacion\n",
    "max = ((data_prophet['y'].max())//1000)+2 #((data_prophet['y'].max())//500)+2#\n",
    "bins = [0]\n",
    "labels = []\n",
    "for i in range(max):\n",
    "    bins.append((i+1)*1000)\n",
    "    labels.append(i)\n",
    "data_prophet['y'] = pd.cut(data_prophet['y'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins = [0]\n",
    "labels = []\n",
    "for i in range(max):\n",
    "    bins.append((i+1)*1000)\n",
    "    labels.append(i)\n",
    "daily_counts_full['Accesos'] = pd.cut(daily_counts_full['Accesos'], bins=bins, labels=labels, right=False)\n",
    "#data_prophet.reset_index(drop=True)\n",
    "\n",
    "data_prophet = data_prophet.drop(['Fecha'], axis=1)\n",
    "\n",
    "# Conjunto completo de features (exógenas/regresores)\n",
    "FEATURES = ['Semana_Certamen', 'media_movil_7', 'media_movil_14', 'media_movil_30',\n",
    "            'mes_sin', 'mes_cos', 'dia_semana_sin', 'dia_semana_cos',\n",
    "            'lag_7', 'lag_14', 'lag_21', 'ewma_7', 'ewma_14', 'ewma_30']\n",
    "\n",
    "# C. División de datos original (sin Augmentation)\n",
    "split_point = int(len(data_prophet) * 0.8)\n",
    "\n",
    "train_df = data_prophet.iloc[:split_point]\n",
    "test_df = data_prophet.iloc[split_point:]\n",
    "\n",
    "y_test = test_df['y']\n",
    "X_test = test_df.drop(columns=['y','Año','Semestre'])\n",
    "\n",
    "y_train = train_df['y']\n",
    "X_train = train_df.drop(columns=['y','Año','Semestre'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35650815-f8cd-4af7-99fa-4a709b41badc",
   "metadata": {},
   "source": [
    "# Visualizacion de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0277eb-518b-4d50-ad16-989f2cfe464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Preparación de Datos Finalizada ---\")\n",
    "print(f\"Prophet: Datos de entrenamiento: {len(train_df)} | Datos de prueba: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbce5d5-476d-42bd-98c5-4d5f78ffa868",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prophet.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6d29c-7df2-4692-a6cb-5c4e56475444",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Nuevas columnas creadas \\n\")\n",
    "\n",
    "# Columnas originales del dataset base\n",
    "columnas_originales = ['Fecha', 'Día', 'Mes', 'Año', 'Vacaciones', 'Accesos']\n",
    "\n",
    "# Mostrar todas las columnas actuales\n",
    "columnas_actuales = list(df.columns)\n",
    "nuevas_columnas = [col for col in columnas_actuales if col not in columnas_originales]\n",
    "\n",
    "print(\" Dataset original - Columnas iniciales:\")\n",
    "print(f\"   Columnas: {columnas_originales}\")\n",
    "print(f\"   Total: {len(columnas_originales)} columnas\\n\")\n",
    "\n",
    "print(\" Nuevas columnas agregadas:\")\n",
    "for i, col in enumerate(nuevas_columnas, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(f\" Resumen de columnas\")\n",
    "print(f\" Columnas originales: {len(columnas_originales)}\")\n",
    "print(f\" Nuevas columnas: {len(nuevas_columnas)}\")\n",
    "print(f\" Total final: {len(columnas_actuales)} columnas\")\n",
    "print(f\" Shape del dataset: {df.shape}\")\n",
    "\n",
    "print(f\" Categorías de nuevas características:\")\n",
    "print(\"  Variables de tendencia: media_movil_7, media_movil_14, media_movil_30\")\n",
    "print(\"  Variables cíclicas: mes_sin, mes_cos, dia_semana_sin, dia_semana_cos\") \n",
    "print(\"  Medias exponenciales: ewma_7, ewma_14, ewma_30\")\n",
    "print(\"  Variables académicas: Semestre, Semana_Semestre, Semana_Certamen\")\n",
    "print(\"  Variables lag: lag_7, lag_14, lag_21 (se agregarán después)\")\n",
    "\n",
    "# Mostrar una muestra del dataset con las nuevas columnas\n",
    "print(\"\\n Muestra del Dataset con nuevas columnas:\")\n",
    "print(df[['Fecha', 'Accesos'] + nuevas_columnas[:5]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9c8eb-ce06-49e4-84f3-69241b95324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Fecha'], df['Accesos'], linestyle='-', color='b', alpha=0.5)\n",
    "\n",
    "# Puntos normales (no vacaciones ni sábados)\n",
    "no_vac_no_sab = (df['Vacaciones?'] == 0) & (df['Fecha'].dt.weekday != 5)\n",
    "plt.scatter(df['Fecha'][no_vac_no_sab], df['Accesos'][no_vac_no_sab], color='b', label='Día normal')\n",
    "\n",
    "# Puntos de vacaciones\n",
    "vac = (df['Vacaciones?'] == 1)\n",
    "plt.scatter(df['Fecha'][vac], df['Accesos'][vac], color='r', label='Vacaciones?')\n",
    "\n",
    "# Puntos de sábados\n",
    "sab = (df['Vacaciones?'] == 0) & (df['Fecha'].dt.weekday == 5)\n",
    "plt.scatter(df['Fecha'][sab], df['Accesos'][sab], color='g', label='Sábado')\n",
    "\n",
    "plt.title('Accesos Diarios a la Universidad')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Número de Accesos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1b025-7d8d-45a5-b6cb-76be9ac8287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de coorrelación\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Matriz de Correlación de Variables', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad78288-1960-4ba4-ac7f-af449bd6a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset final después de ingeneiría de características\\n\")\n",
    "\n",
    "# Mostrar todas las columnas finales organizadas por categoría\n",
    "print(\"Columnas organizadas por categoría:\")\n",
    "\n",
    "print(\"\\n Variables originales:\")\n",
    "originales = ['Fecha', 'Día', 'Mes', 'Año', 'Vacaciones', 'Accesos']\n",
    "for col in originales:\n",
    "    if col in df.columns:\n",
    "        print(f\" {col}\")\n",
    "\n",
    "print(\"\\n Variables de tendencia/suavizado:\")\n",
    "tendencia = [col for col in df.columns if 'media_movil' in col or 'ewma' in col]\n",
    "for col in tendencia:\n",
    "    print(f\" {col}\")\n",
    "\n",
    "print(\"\\n Variables cíclicas/temporales:\")\n",
    "ciclicas = [col for col in df.columns if any(x in col for x in ['sin', 'cos'])]\n",
    "for col in ciclicas:\n",
    "    print(f\" {col}\")\n",
    "\n",
    "print(\"\\n Variables del contexto académico:\")\n",
    "academicas = [col for col in df.columns if any(x in col for x in ['Semestre', 'Semana', 'Certamen'])]\n",
    "for col in academicas:\n",
    "    print(f\" {col}\")\n",
    "\n",
    "print(\"\\n Variables lag (retardos temporales):\")\n",
    "lags = [col for col in df.columns if 'lag_' in col]\n",
    "for col in lags:\n",
    "    print(f\" {col}\")\n",
    "\n",
    "print(f\"\\n Resumen Final:\")\n",
    "print(f\" Total de columnas: {len(df.columns)}\")\n",
    "print(f\" Filas en el dataset: {len(df)}\")\n",
    "print(f\" Nuevas características creadas: {len(df.columns) - 6}\")  # 6 son las originales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139aefa-6c36-4da2-9e55-f912640e38d2",
   "metadata": {},
   "source": [
    "# Funciones Utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681f4a8-50be-4552-b2d3-c3a49dbdec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_pred(Y_pred, Model):\n",
    "    results_df = pd.DataFrame({\n",
    "        'Índice': X_test.index,\n",
    "        'Real': y_test,\n",
    "        'Predicción': Y_pred\n",
    "    }).sort_values(by='Índice')\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results_df['Índice'], results_df['Real'], label='Real', color='blue', linewidth=2)\n",
    "    plt.plot(results_df['Índice'], results_df['Predicción'], label='Predicción', color='green', linestyle='--', linewidth=2)\n",
    "    plt.title('Resultados de Predicción', fontsize=14)\n",
    "    plt.xlabel('Índice', fontsize=12)\n",
    "    plt.ylabel('Número de Accesos', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(f'{Model}_predicciones.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bec238-ab50-427c-ae53-fe5558387c09",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d3fbb-e30a-4ef3-8e32-6c7f69f3c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('Archivos Auxiliares', exist_ok=True)\n",
    "if \"modelo_RandomForest.pkl\" not in os.listdir('Archivos Auxiliares'):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 300, 500, 1000],\n",
    "        'max_depth': [3, 5, 8, None],\n",
    "        'min_samples_split': [2, 5, 8, 10],\n",
    "        'min_samples_leaf': [1, 2, 4, 8],\n",
    "        'max_features': [None, 'sqrt', 'log2', 0.8, 0.4]\n",
    "    }\n",
    "    grid_search = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "        param_grid,\n",
    "        cv=tscv,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=2 # Aumentamos el verbose para seguir mejor el progreso\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "    model = RandomForestClassifier(**best_params, random_state=42, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, 'Archivos Auxiliares/modelo_RandomForest.pkl')\n",
    "    print(\"Modelo guardado como 'Archivos Auxiliares/modelo_RandomForest.pkl'\")\n",
    "else:\n",
    "    model = joblib.load('Archivos Auxiliares/modelo_RandomForest.pkl')\n",
    "    print(\"Modelo cargado desde 'Archivos Auxiliares/modelo_RandomForest.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7847f-1747-412d-9eb3-605a7df0f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de las características\n",
    "importancias = model.feature_importances_\n",
    "indices = np.argsort(importancias)[::-1]\n",
    "print(\"\\n Importancia de las características \\n\")\n",
    "for i in range(X.shape[1]):\n",
    "    print(f\"{i + 1:2d}. {X.columns[indices[i]]}: {importancias[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9125be-91ea-4b19-9b4e-f6bf15666f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar características con importancia menor a 0.01\n",
    "umbral_importancia = 0.01\n",
    "caracteristicas_seleccionadas = X.columns[importancias >= umbral_importancia]\n",
    "X_train = X_train[caracteristicas_seleccionadas]\n",
    "X_test = X_test[caracteristicas_seleccionadas]\n",
    "\n",
    "#Reentrenar el modelo con las características seleccionadas\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36908995-6e15-4bbf-aa18-ed586bc759d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c8751-8ca1-49fd-a645-6cb76cf99cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_pred(Y_pred, 'RandomForest_C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae4aee-2852-4e0d-828b-301070869054",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(16, 8)) \n",
    "\n",
    "plt.plot(\n",
    "    df['Fecha'],\n",
    "    df['Accesos'],\n",
    "    label='Datos Reales (Observados)',\n",
    "    color='#1f77b4',\n",
    "    linewidth=2.5,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    df['Fecha'].loc[X_test.index],\n",
    "    Y_pred,\n",
    "    label='Predicción (Test)',\n",
    "    color='#d62728',\n",
    "    linestyle='--',\n",
    "    linewidth=2.5,\n",
    "    marker='o',\n",
    "    markersize=5,\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "plt.xlabel('Fecha', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Número de Accesos', fontsize=14, labelpad=10)\n",
    "plt.title(\n",
    "    'Rendimiento del Modelo: Predicciones vs. Valores Reales',\n",
    "    fontsize=18,\n",
    "    fontweight='bold',\n",
    "    pad=20\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "\n",
    "# Leyenda y Rejilla\n",
    "plt.legend(loc='upper left', fontsize=12, frameon=True, shadow=True)\n",
    "plt.grid(True, axis='both', linestyle='-', alpha=0.5)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "f1_score(y_test, Y_pred, average='weighted')\n",
    "print(classification_report(y_test, Y_pred))\n",
    "print(confusion_matrix(y_test, Y_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, Y_pred, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d03740-480c-4d9b-92fc-401da749777f",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36245d3-310f-4f94-b59c-5c8ee80273f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('Archivos Auxiliares', exist_ok=True)\n",
    "if \"modelo_LightGBM.pkl\" not in os.listdir('Archivos Auxiliares'):\n",
    "    NUM_CLASS = df['Accesos'].max()+1\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.005, 0.01, 0.05, 0.1, 0.2],\n",
    "        'n_estimators': [100, 300, 500, 1000, 2000],\n",
    "        'num_leaves': [16, 32, 64, 128],\n",
    "        # opcional (incluye solo si sospechas overfit)\n",
    "        'max_depth': [5, 8, 10, 15],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "    print(\"\\nIniciando entrenamiento y ajuste de hiperparámetros de LightGBM...\")\n",
    "\n",
    "    # 1. Búsqueda de Hyperparámetros\n",
    "    grid_search = GridSearchCV(\n",
    "        lgb.LGBMClassifier(num_class=NUM_CLASS,random_state=42, n_jobs=-1, objective='multiclass'),\n",
    "        param_grid,  # Usando el conjunto de parámetros mejorado\n",
    "        cv=tscv,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=2 # Aumentamos el verbose para seguir mejor el progreso\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f'Mejores parámetros para LightGBM: {grid_search.best_params_}')\n",
    "\n",
    "    # 2. Entrenamiento del modelo final con los mejores parámetros\n",
    "    best_params = grid_search.best_params_\n",
    "    model = lgb.LGBMClassifier(**best_params, num_class=NUM_CLASS, random_state=42, n_jobs=-1, objective='multiclass', metric='multi_logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, 'Archivos Auxiliares/modelo_LightGBM.pkl')\n",
    "    print(\"Modelo LightGBM guardado como 'Archivos Auxiliares/modelo_LightGBM.pkl'\")\n",
    "# Guardar el modelo\n",
    "else:\n",
    "    model = joblib.load('Archivos Auxiliares/modelo_LightGBM.pkl')\n",
    "    print(\"Modelo LightGBM cargado desde 'Archivos Auxiliares/modelo_LightGBM.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b9b1f-1d34-4b55-83b5-599fd85dd5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de las características\n",
    "importancias = model.feature_importances_\n",
    "indices = np.argsort(importancias)[::-1]\n",
    "print(\"\\nImportancia de las características\\n\")\n",
    "for i, idx in enumerate(indices):\n",
    "    if idx < len(X.columns):\n",
    "        print(f\"{i + 1:2d}. {X.columns[idx]}: {importancias[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818002ba-de47-4f92-9405-5001f4d9a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar características con importancia menor a 50\n",
    "umbral_importancia = 50\n",
    "\n",
    "# Solo considera las columnas usadas por el modelo y presentes en X_train/X_test\n",
    "columnas_modelo = X.columns[:len(importancias)]\n",
    "FEATURES = [col for col, imp in zip(columnas_modelo, importancias) \n",
    "            if imp >= umbral_importancia and col in X_train.columns and col in X_test.columns]\n",
    "\n",
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]\n",
    "\n",
    "# Reentrenar el modelo con las características seleccionadas\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522043c6-80f3-4b86-b161-04cb85384e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048547e-1cea-4247-a92e-dbcb5a3eb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_pred(Y_pred, 'LightGBM_C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400d366-1805-48ee-a521-3553be599454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar importancia de variables\n",
    "importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({\"Feature\": FEATURES, \"Importance\": importances})\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color='skyblue')\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"LightGBM: Importancia de variables\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.tight_layout()\n",
    "plt.savefig('lightgbm_importancia.png')\n",
    "\n",
    "print(\"\\nSe han generado las siguientes visualizaciones:\")\n",
    "print(\"- lightgbm_predicciones.png (Comparación de valores reales vs. predichos)\")\n",
    "print(\"- lightgbm_importancia.png (Importancia de las variables)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20fc0a6-3f45-4e80-852e-bb68ed851622",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5a729-92ca-4743-8b17-bc77df090e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('Archivos Auxiliares', exist_ok=True)\n",
    "if \"modelo_CatBoost.pkl\" not in os.listdir('Archivos Auxiliares'):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    param_grid = {\n",
    "        'iterations': [100, 300, 500, 1000],\n",
    "        'learning_rate': [0.005, 0.01, 0.05, 0.1, 0.2],\n",
    "        'depth': [4, 6, 8],\n",
    "        'l2_leaf_reg': [1, 3, 5],\n",
    "    }\n",
    "\n",
    "    print(\"\\nIniciando entrenamiento y ajuste de hiperparámetros de CatBoost...\")\n",
    "\n",
    "    # 1. Búsqueda de Hyperparámetros\n",
    "    grid_search = GridSearchCV(\n",
    "        CatBoostClassifier(loss_function='MultiClass', eval_metric='MultiClass', random_state=42, verbose=0),\n",
    "        param_grid,  # Usando el conjunto de parámetros mejorado\n",
    "        cv=tscv,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=2 # Aumentamos el verbose para seguir mejor el progreso\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f'Mejores parámetros para CatBoost: {grid_search.best_params_}')\n",
    "\n",
    "    # 2. Entrenamiento del modelo final con los mejores parámetros\n",
    "    best_params = grid_search.best_params_\n",
    "    model = CatBoostClassifier(**best_params, loss_function='MultiClass', eval_metric='MultiClass', random_state=42, verbose=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, 'Archivos Auxiliares/modelo_CatBoost.pkl')\n",
    "    print(\"Modelo CatBoost guardado como 'Archivos Auxiliares/modelo_CatBoost.pkl'\")\n",
    "# Guardar el modelo\n",
    "else:\n",
    "    model = joblib.load('Archivos Auxiliares/modelo_CatBoost.pkl')\n",
    "    print(\"Modelo CatBoost cargado desde 'Archivos Auxiliares/modelo_CatBoost.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e8549-f277-4b84-b70f-bef500d6d3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de las características\n",
    "importancias = model.get_feature_importance()\n",
    "indices = np.argsort(importancias)[::-1]\n",
    "print(\"\\nImportancia de las características\\n\")\n",
    "for i, idx in enumerate(indices):\n",
    "    if idx < len(X.columns):\n",
    "        print(f\"{i + 1:2d}. {X.columns[idx]}: {importancias[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650b20d-e287-407c-ab80-045752fb43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar características con importancia menor a 5\n",
    "umbral_importancia = 5\n",
    "\n",
    "# Solo considera las columnas usadas por el modelo y presentes en X_train/X_test\n",
    "columnas_modelo = X.columns[:len(importancias)]\n",
    "FEATURES = [col for col, imp in zip(columnas_modelo, importancias) \n",
    "            if imp >= umbral_importancia and col in X_train.columns and col in X_test.columns]\n",
    "\n",
    "X_train = X_train[FEATURES]\n",
    "X_test = X_test[FEATURES]\n",
    "\n",
    "# Reentrenar el modelo con las características seleccionadas\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4b903-4248-4e3f-9cd1-3b60a0540d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9ef14-0a3b-475b-ac5f-d24a076681ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_pred(Y_pred, 'CatBoost_C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40c599-f3fd-4546-b557-97282d1b3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar importancia de variables\n",
    "importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({\"Feature\": FEATURES, \"Importance\": importances})\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color='skyblue')\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"CatBoost: Importancia de variables\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.tight_layout()\n",
    "plt.savefig('CatBoost_importancia.png')\n",
    "\n",
    "print(\"\\nSe han generado las siguientes visualizaciones:\")\n",
    "print(\"- CatBoost_predicciones.png (Comparación de valores reales vs. predichos)\")\n",
    "print(\"- CatBoost_importancia.png (Importancia de las variables)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79bc859-0e94-4431-ae8e-f5967bf5a26b",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9cc2a-c6de-4391-97a8-701184f49746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
